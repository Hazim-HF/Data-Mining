hist(z_score_hpa, col = 'bisque3', main = 'Histogram of Normalize Data')
z = function (x) {
mean = mean(x)
sd = sd(x)
z = (x - mean)/sd
hist(z, col = 'aquamarine4')
return(z)
}
z(dataAP3$pressure_height.hPA)
pHnew = dataAP3$pressure_height.hPA/1000
head(pHnew)
pHnew = dataAP3$pressure_height.hPA/1000
head(pHnew)
hist(pHnew)
pHnew = dataAP3$pressure_height.hPA/1000
head(pHnew)
hist(pHnew, col = 'bisque3')
hist(dataAP3$pressure_height.hPA, col = 'skyblue', main = 'Histogram of Pressure Height (hPA)', xlab = 'Pressure Height')
dataAP3$Visibility_pAerosol
hist(dataAP3$Visibility_pAerosol)
vis2 = sqrt(dataAP3$Visibility_pAerosol)
hist(vis2)
dataAP3$Visibility_pAerosol
hist(dataAP3$Visibility_pAerosol, col = 'skyblue')
vis2 = sqrt(dataAP3$Visibility_pAerosol)
hist(vis2, col = 'bisque3')
vis2 = log(dataAP3$Visibility_pAerosol)
hist(vis2, col = 'bisque3')
vis2 = ataAP3$Visibility_pAerosol ** 2
vis2 = dataAP3$Visibility_pAerosol ** 2
hist(vis2, col = 'bisque3')
par(mfrow=c(1,2))
hist(vis2, col = 'bisque3')
boxplot(vis2, col = 'bisque3')
vis2 = sqrt(dataAP3$Visibility_pAerosol)
hist(vis2, col = 'bisque3')
par(mfrow=c(1,2))
hist(vis2, col = 'bisque3')
boxplot(vis2, col = 'bisque3')
qqnorm(vis2, col = 'bisque4')
?ks.test
ks.test(vis2)
ks.test(vis2, 'pnorm')
ks.test(vis2, 'pnorm', mean = mean(vis2), sd = sd(vis2))
shapiro.test(vis2)
ad.test(vis2)
library(nortest)
install.packages('nortest')
library(nortest)
ad.test(vis2)
library(infotheo)
data("USArrests")
attach(USArrests)
USArrests
# alternative way
cut(USArrests$Murder, breaks = c(max(USArrests$Murder), 10, max(USArrests$Murder)))
# alternative way
cut(USArrests$Murder, breaks = c(min(USArrests$Murder), 10, max(USArrests$Murder)))
?cut
# alternative way
cut(USArrests$Murder,
breaks = c(min(USArrests$Murder), 10, max(USArrests$Murder)),
labels = c('Low Risk', 'High Risk'))
SArrests$Murder
USArrests$Murder
# alternative way
cut(USArrests$Murder,
breaks = c(min(USArrests$Murder), 10, max(USArrests$Murder)),
labels = c('Low Risk', 'High Risk'))
USArrests$Murder
min(USArrests$Murder)
max(USArrests$Murder)
USArrests$Murder
# alternative way
cut(USArrests$Murder,
breaks = c(min(USArrests$Murder)-1, 10, max(USArrests$Murder)),
labels = c('Low Risk', 'High Risk'))
# alternative way
cut(USArrests$Murder,
breaks = c(min(USArrests$Murder)-1, 10, max(USArrests$Murder)),
labels = c('Low Risk', 'High Risk'))
library(car)
status_den = Recode(UrbanPop, "0:50 = 'Low Density';
51:70 = 'Moderate Density';
else = 'High Density'")
head(status_den)
cut(USArrests$Murder,
breaks = c(min(USArrests$Murder)-1, 10, max(USArrests$Murder)))
cut(USArrests$Murder,
breaks = c(min(USArrests$Murder), 10, max(USArrests$Murder)))
assault_status = discretize(Assault, 'equalwidth', 4)
unique(assault_status)
head(assault_status)
barplot(table(assault_status$X))
hist(assault_status$X)
barplot(table(discretize(Assault, 'equalfreq', 4)$X))
discretize(Assault, 'equalfreq', 4)
barplot(table(discretize(Assault, 'equalfreq', 4)))
X
barplot(table(discretize(Assault, 'equalfreq', 4)$X))
datalocal = read.csv('./Data/dataLocal.csv')
head(data)
head(datalocal)
datalocal = read.csv('./Data/dataLocal.csv', sep = ';')
head(datalocal)
hist(datalocal[,1])
par(mfrow=c(1,2))
hist(datalocal[,1])
hist(datalocal[,2])
model = kmeans(datalocal[,1], k = 3)
model = kmeans(datalocal[,1], 3)
?model
?kmeans
model = kmeans(datalocal[,1], 3)
hist(data[,1], col = model)
model = kmeans(datalocal[,1], 3)
hist(datalocal[,1], col = model)
model
hist(model, col = model)
hist(model)
model = as.factor(model)
model = as.factor(model$cluster)
hist(model)
hist(model)
model = as.factor(model$cluster)
hist(model)
model = as.factor(model$cluster)
model = kmeans(datalocal[,1], 3)
model = as.factor(model$cluster)
hist(model)
model
model = kmeans(datalocal[,1], 3)
km = as.factor(model$cluster)
hist(model$cluster, col = km)
par(mfrow=c(1,2))
hist(datalocal[,1])
hist(datalocal[,2])
par(mfrow=c(1,2))
hist(datalocal[,1], col = 'bisque4')
hist(datalocal[,2], col = 'bisque4')
par(mfrow=c(1,2))
hist(datalocal[,1], col = 'bisque3')
hist(datalocal[,2], col = 'bisque3')
cutoff = 10 # Need domain explanation
status_m = ifelse(Murder<10,'Low Risk','High Risk')
head(status_m)
# alternative way
cut(USArrests$Murder,
breaks = c(min(USArrests$Murder), 10, max(USArrests$Murder)),
labels = c('Low Risk', 'High Risk'))
?KNNimp
mdata = read.csv('./Data/Mdata.csv')
mdata = read.csv('./Data/Mdata.csv')
head(mdata)
mdata = read.csv('./Data/Mdata.csv', sep = ';')
head(mdata)
md.pattern(mdata)
library(mice)
md.pattern(mdata)
md.pattern(na.omit(mdata))
# alternative way
mdata[complete.cases(mdata)]
complete.cases(mdata)
# alternative way
mdata[complete.cases(mdata), ]
# alternative way
mdata[complete.cases(mdata), ]
mdata[!complete.cases(mdata), ]
na.omit(mdata)
# alternative way to filter only data without any missing value
mdata[complete.cases(mdata), ]
head(na.omit(mdata))
# alternative way to filter only data without any missing value
head(mdata[complete.cases(mdata), ])
# see all rows of data with missing value in at least one of its attribute
head(mdata[!complete.cases(mdata), ])
edit(mdata)
edit(mdata$indus)
head(edit(mdata))
par(mfrow=c(1,3))
hist(mdata$indus, col = 'skyblue', main = 'Indus')
hist(mdata$crim)
hist(mdata$medv)
par(mfrow=c(1,3))
hist(mdata$indus, col = 'skyblue', main = 'Indus', xlab = 'Indus')
hist(mdata$crim, col = 'bisque3', main = 'Crim', xlab = 'Crim')
hist(mdata$medv, col = 'aquamarine4', main = 'Medv', xlab = 'Medv')
ifelse(mdata$indus = NA, 'yay')
ifelse(mdata$indus == NA, 'yay')
mdata$indus
ifelse(is.na(mdata$indus), median(mdata$indus, na.rm = T), mdata$indus)
# imputate using median of the centralized metric
indus_imp = ifelse(is.na(mdata$indus), median(mdata$indus, na.rm = T), mdata$indus)
# imputate using median of the centralized metric
indus_imp = ifelse(is.na(mdata$indus), median(mdata$indus, na.rm = T), mdata$indus)
# compare the data distribution before and after imputation
par(mfrow=c(1,2))
hist(mdata$indus, col = 'magenta', main = 'Original Data')
hist(indus_imp, col = 'darkblue', main = 'Data with esimated missing value')
# imputate using median of the centralized metric
indus_imp = ifelse(is.na(mdata$indus), median(mdata$indus, na.rm = T), mdata$indus)
# compare the data distribution before and after imputation
par(mfrow=c(1,2))
hist(mdata$indus, col = 'magenta', main = 'Original Data', xlab = 'Indus')
hist(indus_imp, col = 'darkblue', main = 'Imputed Data', xlab = 'Indus')
read.csv('./Data/iris.mis1.csv')
iris.mis1 = read.csv('./Data/iris.mis1.csv')
head(iris.mis1)
?KNNimp
install.packages('multiUS')
library(multiUS)
?KNNimp
read.csv('./Data/airquality.csvl')
read.csv('./Data/airquality.csv')
read.table('./Data/airquality.txt')
airquality = read.table('./Data/airquality.txt')
airquality = read.table('./Data/airquality.txt')
head(airquality)
# predictive mean matching
mice(airquality, m = 5, meth = 'pmm')
md.pattern(airquality)
library(multiUS)
iris_knn = KNNimp(iris.mis1, k = 10)
md.pattern(iris_knn)
# predictive mean matching
air.pmm = mice(airquality, m = 5, meth = 'pmm')
mad.pattern(air.pmm)
# predictive mean matching
air.pmm = mice(airquality, m = 5, meth = 'pmm')
md.pattern(air.pmm)
# predictive mean matching
air.pmm = mice(airquality, m = 5, meth = 'pmm')
md.pattern(complete(air.pmm))
ozone3 = read.csv('./Data/ozone3.csv')
ozone3 = read.csv('./Data/ozone3.csv')
head(ozone3)
par(mfrow=c(2,2))
boxplot(ozone3$ozone_reading, main = 'Ozone Reading', col = 'violet')
boxplot(ozone3$pressure_height, main = 'Pressure Height', col = 'violet')
boxplot(ozone3$Wind_speed, main = 'Wind speed', col = 'violet')
boxplot(ozone3$Humidity, main = 'Humidity', col = 'violet')
par(mfrow=c(2,2))
boxplot(ozone3$ozone_reading, main = 'Ozone Reading', col = 'violet')
boxplot(ozone3$pressure_height, main = 'Pressure Height', col = 'violet')
boxplot(ozone3$Wind_speed, main = 'Wind speed', col = 'violet')
boxplot(ozone3$Humidity, main = 'Humidity', col = 'violet')
boxplot.stats(ozone3$ozone_reading)$out
x = boxplot.stats(ozone3$ozone_reading)$out
length(x)
x
which(ozone3$ozone_reading %in% c(1,2,3))
which
?which
?which(ozone3$ozone_reading %in% boxplot.stats(ozone3$ozone_reading)$out)
which(ozone3$ozone_reading %in% boxplot.stats(ozone3$ozone_reading)$out)
ozone3[c(188, 189, 243), ]
# find the row index for data that contain outlier
out = which(ozone3$ozone_reading %in% boxplot.stats(ozone3$ozone_reading)$out)
ozone3[-out, ]
sort(ozone3[-out, ])
sort(ozone3[-out, ], by = 'ozone_reading')
ozone3[-out, ]
boxplot(ozone_reading~Month, main = "Plot Kotak Bacaan Ozone Bulanan")
boxplot(ozone3$ozone_reading~ozone3$Month,
main = "Plot Kotak Bacaan Ozone Bulanan")
boxplot(ozone3$ozone_reading~ozone3$Month)$out
model = lm(ozone_reading~., data = ozone3)
cooks.distance(model)
model = lm(ozone_reading~., data = ozone3)
cooksd = cooks.distance(model)
plot(cooksd)
model = lm(ozone_reading~., data = ozone3)
cooksd = cooks.distance(model)
plot(cooksd)
min.cook = 4 * mean(cooksd)
abline(h=min.cook)
text(x=1)
model = lm(ozone_reading~., data = ozone3)
cooksd = cooks.distance(model)
plot(cooksd)
min.cook = 4 * mean(cooksd)
abline(h=min.cook)
text(x=1)
model = lm(ozone_reading~., data = ozone3)
cooksd = cooks.distance(model)
plot(cooksd)
min.cook = 4 * mean(cooksd)
abline(h=min.cook)
text(x=1:length(cooksd))
model = lm(ozone_reading~., data = ozone3)
cooksd = cooks.distance(model)
plot(cooksd)
min.cook = 4 * mean(cooksd)
abline(h=min.cook)
text(x=1:length(cooksd), y = cooksd, labels = ifelse(cooksd > min.cook,
names(cooksd), ''),
col = 'blue')
datamus = read.csv('./Data/dataMus.csv')
head(datamus)
mahalanobis(datamus)
mahalanobis(datamus, colMeans(datamus), cov(datamus))
dg = graph_from_literal(KL-+CHINA, KL-+London, CHINA++London)
dg
plot(dg)
?graph_from_literal
g = graph_from_literal(1-2, 1-3, 1-7, 3-4, 2-3, 2-4, 3-5, 4-5,
4-6, 4-7, 5-6, 5-8, 6-7, 7-8)
g
# labelkan nod/verteks
V(g)$name = c('Adam', 'Judy', 'Bobby', 'Sam', 'Frank', 'Tom', 'Jerry',
'Jay')
g
# Plot graf dengan hubungan tak terarah
set.seed(12)
plot(g)
plot(dg)
tr = make_tree(40, children=3, mode='undirected')
plot(tr)
gb = sample_bipartite(10,5,p=0.4)
col = c('blue', 'red')
shape = c('circle', 'square')
plot(gb, vertex.color = col[as.numeric(V(gb)$type+1)],
vertex.shape=shape[as.numeric(V(gb)$type+1)])
library(HyperG)
h = hypergraph_from_edgelist(list(1:2, 2:5, 3:7, c(1,3,5,7,9)))
plot(h)
plot(g)
Adj.list1 = as_adj_list(g)
Adj.list1
h = g- vertices(c('Jerry', 'Bobby'))
h
h2 = graph_from_literal('Adam'-'Judy', 'Adam'-'Tom', 'Judy'-'Aminah',
'Aminah'-'Frank')
plot(h2)
h2 = graph_from_literal('Adam'-'Judy', 'Adam'-'Tom', 'Judy'-'Aminah',
'Aminah'-'Frank')
plot(h2)
h2 = graph_from_literal('Adam'-'Judy', 'Adam'-'Tom', 'Judy'-'Aminah',
'Aminah'-'Frank')
plot(h2)
h2 = graph_from_literal('Adam'-'Judy', 'Adam'-'Tom', 'Judy'-'Aminah',
'Aminah'-'Frank')
plot(h2)
g = graph_from_literal(1-2, 1-3, 1-7, 3-4, 2-3, 2-4, 3-5, 4-5,
4-6, 4-7, 5-6, 5-8, 6-7, 7-8)
g
plot(g)
V(g)$name = c('Adam', 'Judy', 'Bobby', 'Sam', 'Frank', 'Tom', 'Jerry',
'Jay')
plot(g)
h = g- vertices(c('Jerry', 'Bobby'))
h
par(mfrow=c(1,2))
plot(g)
plot(h)
h3 = union(h2, g)
plot(h3)
V(h3)
V(h3)$gender = c('male', 'female', 'male', 'female', 'male', 'male', 'male',
'male', 'female')
h3
plot(h3)
h3
g
h3
vertex_attr(h3)
E(h3)
plot(h3)
E(h3)
V(h3)
E(h3)$type = c('email', 'phone', 'FB', 'email', 'class', 'Twitter', 'neighbor',
'phone', 'FB', 'email', 'class', 'neighbor', 'phone', 'email',
'email', 'FB', 'neighbor')
edge_attr(h3)
vertex_attr(h3)
edge_attr(h3)
E(h3)$weight = c(10,1,3,2,2,2,1,5,9,8,1,6,2,9,3,10,7)
edge_attr(h3)
plot(h3, vertex.label=V(h3)$gender, edge.label = E(h3)$type)
plot(h3)
plot(h3, vertex.label=V(h3)$gender, edge.label = E(h3)$type)
plot(h3, vertex.label=V(h3)$name, edge.label = E(h3)$weight)
data(Bali)
#par(mar=c(1,1,1,1))
plot(Bali, displaylabels = T)
library(devtools)
install_github('DougLuke/UserNetR')
library(UserNetR)
data(Bali)
#par(mar=c(1,1,1,1))
plot(Bali, displaylabels = T)
data(Bali)
#par(mar=c(1,1,1,1))
plot(Bali, displaylabels = T)
data(Bali)
par(mar=c(1,1,1,1))
plot(Bali, displaylabels = T)
Bali
name = Bali%v%'vertex.names'
library(UserNetR)
data(Bali)
Bali
head(Bali)
data(Bali)
par(mar=c(1,1,1,1))
plot(Bali)
data = read.csv(file.choose())
head(data)
colSums(is.na(data))
?transactions
library(arules)
?transactions
data2 = transactions(data)
head(data2)
inspect(head(data2))
data2 = transactions(data, format = 'long')
inspect(head(data2))
data2 = transactions(data, format = 'long', cols = c('TransactionID', 'Item'))
data3 = read.transactions(file.choose())
inspect(head(data3))
split(data$TransactionID, data$Item)
data(package=TraMiner)
library(TraMineR)
data(package=TraMiner)
data(package='TraMiner')
library(TraMineR)
data(package='TraMiner')
data('package=TraMiner')
data('package=TraMiner')
data(package='TraMiner')
data(package='TraMineR')
data(actcal)
class(actcal)
head(actcal)
?TarMineR
?TarMineR
??TarMineR
library(tm)
library(SnowballC)
library(wordcloud)
library(RColorBrewer)
library(syuzhet)
library(ggplot2)
# error occurs due to the file does not end with newline
text = readLines('./Data/text.txt')
class(text)
# after we add new line at the end, no warning will appear
readLines('./Data/newtext.txt')
docs = Corpus(VectorSource(text))
inspect(docs)
library(tm)
library(SnowballC)
library(wordcloud)
library(RColorBrewer)
library(syuzhet)
library(ggplot2)
# error occurs due to the file does not end with newline
text = readLines('./Data/text.txt')
class(text)
# after we add new line at the end, no warning will appear
readLines('./Data/newtext.txt')
docs = Corpus(VectorSource(text))
inspect(docs)
docs = Corpus(VectorSource(text))
inspect(docs)
class(docs)
toSpace = content_transformer(function(x, pattern)
gsub(pattern, '', x))
toSpace
docs2 = tm_map(docs, toSpace, '!')
docs2 = tm_map(docs, toSpace, '!')
docs2
docs2 = tm_map(docs, toSpace, '!')
docs3 = tm_map(docs2, toSpace, ':')
docs4 = tm_map(docs3, toSpace, ',')
docs5 = tm_map(docs4, content_transformer(tolower))
library(tm)
library(SnowballC)
library(wordcloud)
library(RColorBrewer)
library(syuzhet)
library(ggplot2)
# error occurs due to the file does not end with newline
text = readLines('./Data/text.txt')
class(text)
# after we add new line at the end, no warning will appear
readLines('./Data/newtext.txt')
docs = Corpus(VectorSource(text))
#inspect(docs)
class(docs)
toSpace = content_transformer(function(x, pattern)
gsub(pattern, '', x))
docs2 = tm_map(docs, toSpace, '!')
docs3 = tm_map(docs2, toSpace, ':')
docs4 = tm_map(docs3, toSpace, ',')
docs5 = tm_map(docs4, content_transformer(tolower))
docs6 = tm_map(docs5, removeNumbers)
docs7 = tm_map(docs6, removeWords, stopwords('english'))
docs8 = tm_map(docs7, removePunctuation)
docs9 = tm_map(docs8, stripWhitespace)
docs10 = tm_map(docs9, stemDocument)
dtm = TermDocumentMatrix(docs10)
m = as.matrix(dtm)
m
dim(m)
v = sort(rowSums(m), decreasing = T)
v
d = data.frame(word = names(v), freq = v)
d
library(sentimentr)
x = 'Sentiment analysis is super fun'
sentiment(x)
