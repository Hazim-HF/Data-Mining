---
title: "Data Cleaning"
author: "Hazim Fitri"
date: "2024-12-17"
output: pdf_document
---

# Data Cleaning

Data cleaning involves in dealing with:

1.  Missing data
2.  Inconsistent data
3.  Outlier

There are several method to deal with missing data such as:

1.  Identify pattern
2.  Remove missing data
3.  Fill manually
4.  Use centralized metric
5.  K-Nearest Neighbor
6.  Statistical imputation

```{r}
library(mice)
mdata = read.csv('MData.csv', sep=';')
head(mdata)
```

```{r}
md.pattern(mdata)
```

Remove rows that contain missing value.

```{r}
mdata2 = mdata[complete.cases(mdata),]
mdata[!complete.cases(mdata),]
```

```{r}
mdata$indus
#edit(mdata$indus)
mdata
```

Impute data using Central measure (median)

```{r}
median(mdata$crim, na.rm=T)
mdata$crim = ifelse(is.na(mdata$crim), median(mdata$crim, na.rm=T), mdata$crim)
mdata
```

`na.rm` argument ask the user whether the missing value should be remove before computing the median

```{r}
par(mfrow=c(1,3))
hist(mdata$crim)
hist(mdata$indus)
hist(mdata$medv)
```

We can see that all three histogram is not symmetry.

# K-Nearest Neighbor

```{r}
iris_mis1 = read.csv('iris.mis1.csv')
iris_mis1
```

```{r}
library(multiUS)
iris_knn = KNNimp(data=iris_mis1, k=10)
iris_knn
```

# Statistical Method

```{r}
airquality = read.table('airquality.txt')

```
