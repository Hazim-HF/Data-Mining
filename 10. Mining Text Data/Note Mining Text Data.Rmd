---
title: "Mining Text Data"
author: "Hazim Fitri"
date: "2025-01-05"
output: 
  pdf_document:
    toc: true
    toc_depth: 6
---

# Steps of cleaning text data.

1.   Remove special characters from the text, where a symbol such as; /, @ and \| will be replace by a space.
2.  Convert the text to lower case.
3.  Remove numbers
4.  Remove the stopwords in text data. Example: Stopwords in English are “the, is, at, on”. There is no single universal list of stopwords used by all NLP tools.
5.  Remove punctuation.
6.  Eliminate extra unnecessary spaces in the text.

```{r, warning = FALSE}
library(tm)
library(SnowballC)
library(wordcloud)
library(RColorBrewer)
library(syuzhet)
library(ggplot2)
```

```{r}
text = readLines('text.txt')
class(text)
```

# Transform into Corpus

```{r}
docs = Corpus(VectorSource(text))
inspect(docs)
```

```{r}
class(docs)
```

## Replace special characters with space

Remove special characters

```{r}
toSpace = content_transformer(function(x, pattern)
  gsub(pattern, '', x))


```

replace

```{r}
docs2 = tm_map(docs, toSpace, '!')
docs3 = tm_map(docs2, toSpace, ':')
docs4 = tm_map(docs3, toSpace, ',')
```

## Convert Capital letter to Small letter

```{r}
docs5 = tm_map(docs4, content_transformer(tolower))
```

## Remove number

```{r}
docs6 = tm_map(docs5, removeNumbers)
```

## Remove stopwords (the, is, at, on)

```{r}
docs7 = tm_map(docs6, removeWords, stopwords('english'))
```

## Remove punctuation

```{r}
docs8 = tm_map(docs7, removePunctuation)
```

## Remove extra spaces

```{r}
docs9 = tm_map(docs8, stripWhitespace)
```

# Text stemming

Find the root word

```{r}
docs10 = tm_map(docs9, stemDocument)
```

# Document term matrix

```{r}
dtm = TermDocumentMatrix(docs10)

m = as.matrix(dtm)

m
```

```{r}
dim(m)
```

There are 162 unique words in 46 line of text

# Word cloud

```{r}
v = sort(rowSums(m), decreasing = T)

v
```

```{r}
d = data.frame(word = names(v), freq = v)

d
```

```{r}
set.seed(12)
wordcloud(words=d$word, freq = d$freq, min.freq = 2, max.words = 150, 
          random.order = F, colors = brewer.pal(8, 'Dark2'))
```

# Word Association

```{r}
findAssocs(dtm, terms = 'freedom', corlimit = 0.3)$freedom
```

```{r}
findAssocs(dtm, terms=findFreqTerms(dtm, lowfreq = 10), corlimit = 0.3)
```

# Sentiment Analysis

```{r}
library(sentimentr)
```

```{r}
x = 'Sentiment analysis is super fun'

sentiment(x)
```

0.67 which is positive shows that the sentiment is positive

```{r}
y = 'sentiment analysis is super boring. But I do love working with R'
sentiment(y)
```

```{r}
sentiment_text = get_sentiment(text, method='syuzhet')

sentiment_text
```

```{r}
hist(sentiment_text)
```

```{r}
summary(sentiment_text)
```

# Emotion classification

The NRC Emotion Lexicon is a list of English correspond to eight basic emotions:

1.  Anger
2.  Fear
3.  Anticipation
4.  Trust
5.  Surprise
6.  Sadness
7.  Joy
8.  Disgust

```{r}
d2 = get_nrc_sentiment(text)

d2
```

```{r}
td = data.frame(t(d2))
td_new = data.frame(rowSums(td))

td_new
```

```{r}
names(td_new)[1] = 'count'

td_new = cbind('sentiment'=rownames(td_new), td_new)

rownames(td_new) = NULL

qplot(sentiment, weight = count, data=td_new, geom = 'bar',
      fill = sentiment,
      ylab = 'count') + ggtitle('Sentiment Score')
```
